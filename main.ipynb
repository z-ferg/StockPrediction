{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad32db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d8c423",
   "metadata": {},
   "source": [
    "# Step 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "177b96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Local Dataset Importing\n",
    "        Originally tried to use the Kaggle API however quickly faced\n",
    "        issues with rate limiting. Local downloading will speed up\n",
    "        training at the cost of repeatability for others viewing project.\n",
    "        \n",
    "        Solution, I pull from downloaded datasets in parent folder to this\n",
    "        github repository. news_data contains only the news dataset .json file,\n",
    "        stock data contains a .csv with the metadata as well as 2 subfolders\n",
    "        ETF and Stocks that contain their respective ticker histories\n",
    "\"\"\"\n",
    "news_path = os.getcwd() + \"/../news_data/\"\n",
    "stock_path = os.getcwd() + \"/../stock_data/\"\n",
    "\n",
    "news_df = pd.read_json(f'{news_path}News_Category_Dataset_v3.json', lines=True)\n",
    "stock_meta = pd.read_csv(f'{stock_path}symbols_valid_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e0d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with stock: AGM$A\n",
      "Error with stock: CARR.V\n",
      "Error with stock: UTX.V\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Capture all Data Frames\n",
    "        Maintain a dictionary with keys as stock ticker symbols and values\n",
    "        as the DataFrames captured from reading the stock's .csv\n",
    "\"\"\"\n",
    "stock_tickers = [x['Symbol'] for _, x in stock_meta.iterrows() if x['ETF'] == 'N'] # Remove ETFs\n",
    "\n",
    "\n",
    "stock_dfs = {}\n",
    "for s in stock_tickers:\n",
    "    try:\n",
    "        stock_dfs[s] = pd.read_csv(f\"{stock_path}/stocks/{s}.csv\")\n",
    "    except Exception:\n",
    "        print(f\"Error with stock: {s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7606494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News Columns: ['link' 'headline' 'category' 'short_description' 'authors' 'date']\n",
      "Stock Columns: ['Date' 'Open' 'High' 'Low' 'Close' 'Adj Close' 'Volume']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Dataset Columns\n",
    "\"\"\"\n",
    "print(f\"News Columns: {news_df.columns.values}\")\n",
    "print(f\"Stock Columns: {stock_dfs['A'].columns.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f1058e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Helper Functions\n",
    "\"\"\"\n",
    "\n",
    "# Return the next trading day, avoiding holidays and weekends\n",
    "#   Inputs\n",
    "#       cur_day      -> The current date\n",
    "#       trading_days -> List of all open dates in the range\n",
    "#   Returns:\n",
    "#       The next available date (datetime object)\n",
    "def next_trading_day(cur_day, trading_days):\n",
    "    days_left = trading_days[trading_days > cur_day]\n",
    "    return days_left.min() if len(days_left) else trading_days.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5209ccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Stocks before processing: \t5881\n",
      "Number of Stocks after processing: \t3511\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Prepare Stock Datasets\n",
    "        Drop irrelevant columns --> High, Low, Volume, adj_close\n",
    "        Drop information prior to 2012-01-28\n",
    "        Create stock return time horizon features\n",
    "\"\"\"\n",
    "processed_stocks = {}\n",
    "tickers = stock_dfs.keys()\n",
    "\n",
    "for s in tickers:\n",
    "    df = stock_dfs[s].copy()\n",
    "\n",
    "    df['Ticker'] = s\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df[df['Date'] >= pd.Timestamp(\"2012-01-28\")].reset_index(drop=True)\n",
    "    df = df.drop(['High', 'Low', 'Adj Close', 'Volume'], axis=1)\n",
    "\n",
    "    if df.shape[0] != 2057: # 2057 dates 2012-01-28 and 2020-04-01, cut unfilled stocks\n",
    "        continue\n",
    "\n",
    "    df['r_0d'] = (df['Close'] - df['Open'])/df['Open']\n",
    "    df['r_1d'] = df['Close'].shift(-1).pct_change(periods=1, fill_method=None)\n",
    "    df['r_7d'] = df['Close'].shift(-7).pct_change(periods=7, fill_method=None)\n",
    "    df['r_30d'] = df['Close'].shift(-30).pct_change(periods=30, fill_method=None)\n",
    "\n",
    "    processed_stocks[s] = df\n",
    "\n",
    "print(f\"Number of Stocks before processing: \\t{len(stock_dfs)}\")\n",
    "print(f\"Number of Stocks after processing: \\t{len(processed_stocks)}\")\n",
    "\n",
    "stock_dfs = {k: v for k, v in processed_stocks.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82939532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date       Open      Close Ticker      r_0d      r_1d  r_7d  r_30d\n",
      "0    2012-01-30  29.992847  30.872675      A  0.029335       NaN   NaN    NaN\n",
      "1    2012-01-31  30.994278  30.379112      A -0.019848  0.040499   NaN    NaN\n",
      "2    2012-02-01  30.815451  31.609442      A  0.025766 -0.010636   NaN    NaN\n",
      "3    2012-02-02  31.623749  31.273247      A -0.011084  0.035682   NaN    NaN\n",
      "4    2012-02-03  31.759657  32.389126      A  0.019820 -0.013693   NaN    NaN\n",
      "...         ...        ...        ...    ...       ...       ...   ...    ...\n",
      "2052 2020-03-26  70.000000  73.720001      A  0.053143 -0.038117   NaN    NaN\n",
      "2053 2020-03-27  71.550003  70.910004      A -0.008945  0.024820   NaN    NaN\n",
      "2054 2020-03-30  71.059998  72.669998      A  0.022657 -0.014449   NaN    NaN\n",
      "2055 2020-03-31  72.339996  71.620003      A -0.009953 -0.037699   NaN    NaN\n",
      "2056 2020-04-01  69.470001  68.919998      A -0.007917       NaN   NaN    NaN\n",
      "\n",
      "[2057 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(stock_dfs['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4aefdb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Prepare News Dataset\n",
    "        News DF starts 2022-09-23, ends 2012-01-28 --> First must reverse dataset\n",
    "        Drop categories to only necessary --> Category, Headline, Date\n",
    "        Shift dates to align with trading days, skipping weekends and holidays till next open day\n",
    "\"\"\"\n",
    "news_df = news_df.sort_values(by='date', ascending=True).reset_index(drop=True)\n",
    "news_df = news_df.drop(['link', 'short_description', 'authors'], axis=1)\n",
    "news_df = news_df[news_df['date'] <= pd.Timestamp(\"2020-04-01\")].reset_index(drop=True)\n",
    "\n",
    "trading_days = pd.to_datetime(stock_dfs['A']['Date'].unique())\n",
    "news_df['effective_date'] = news_df['date'].apply(lambda d: next_trading_day(d, trading_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa29191",
   "metadata": {},
   "source": [
    "# Step 2: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bee106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment of each headline using \n",
    "news_df['sentiment'] = news_df['headline'].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48e083c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiment = (\n",
    "    news_df.groupby(['effective_date', 'category'])\n",
    "    .agg(\n",
    "        avg_sentiment = ('sentiment', 'mean'),\n",
    "        article_count = ('headline', 'count')\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34bfc8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = pd.date_range(news_df['effective_date'].min(), news_df['effective_date'].max())\n",
    "all_cats = news_df['category'].unique()\n",
    "\n",
    "\n",
    "all_cats_per_date = pd.MultiIndex.from_product(\n",
    "    [all_dates, all_cats],\n",
    "    names=['date', 'category']\n",
    ")\n",
    "\n",
    "daily_sentiment = (\n",
    "    daily_sentiment\n",
    "    .set_index(['effective_date', 'category'])\n",
    "    .reindex(all_cats_per_date)\n",
    "    .fillna({'avg_sentiment': 0, 'article_count': 0})\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee6ea1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date        category  avg_sentiment  article_count\n",
      "0      2012-01-30          SPORTS       0.152104            9.0\n",
      "1      2012-01-30         SCIENCE       0.233333            6.0\n",
      "2      2012-01-30          COMEDY       0.014242           11.0\n",
      "3      2012-01-30       PARENTING       0.200000            5.0\n",
      "4      2012-01-30  STYLE & BEAUTY      -0.054545           14.0\n",
      "...           ...             ...            ...            ...\n",
      "125365 2020-04-01       GOOD NEWS       0.000000            0.0\n",
      "125366 2020-04-01  ARTS & CULTURE       0.000000            0.0\n",
      "125367 2020-04-01   THE WORLDPOST       0.000000            0.0\n",
      "125368 2020-04-01      WORLD NEWS       0.000000            0.0\n",
      "125369 2020-04-01       U.S. NEWS       0.000000            0.0\n",
      "\n",
      "[125370 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(type(daily_sentiment))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
