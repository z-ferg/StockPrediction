{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad32db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import ds_helpers as dh\n",
    "import helper_funcs as hf\n",
    "import ml_models as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177b96c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with stock: AGM$A\n",
      "Error with stock: CARR.V\n",
      "Error with stock: UTX.V\n",
      "\n",
      "Number of Stocks before processing: \t5881\n",
      "Number of Stocks after processing: \t3511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(dh)\n",
    "importlib.reload(hf)\n",
    "importlib.reload(ml)\n",
    "\n",
    "# Fetch all datasets\n",
    "news_path = \"/../../news_data/\"\n",
    "stock_path = \"/../../stock_data/\"\n",
    "\n",
    "news_df, stock_meta = dh.fetch_datasets(news_path, stock_path)\n",
    "stock_dfs = dh.fetch_stock_data(stock_meta, stock_path)\n",
    "\n",
    "# Prepare datasets\n",
    "stock_dfs = dh.prep_stock_data(stock_dfs)\n",
    "news_df = dh.prep_news_data(news_df, stock_dfs)\n",
    "\n",
    "# Sentiment Analysis\n",
    "daily_sent = ml.sentiment_analysis(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad3a937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date Ticker       Open      r_0d      r_1d      r_7d     r_30d  \\\n",
      "0       2012-03-13      A  31.444921  0.026160 -0.003104 -0.031035 -0.087120   \n",
      "1       2012-03-13     AA  24.030001  0.031000 -0.002910 -0.029098 -0.047527   \n",
      "2       2012-03-13    AAL   7.000000 -0.005714  0.018678  0.053161  0.379310   \n",
      "3       2012-03-13   AAME   2.900000 -0.017241  0.010526 -0.003509  0.028070   \n",
      "4       2012-03-13    AAN  26.270000  0.011420 -0.013925 -0.029356 -0.042529   \n",
      "...            ...    ...        ...       ...       ...       ...       ...   \n",
      "7011462 2020-02-19   ZNGA   7.100000 -0.001408  0.012694 -0.053597 -0.046544   \n",
      "7011463 2020-02-19    ZNH  30.379999  0.010204 -0.028674 -0.127403 -0.335614   \n",
      "7011464 2020-02-19    ZTR  11.790000  0.004241  0.009291 -0.179054 -0.430743   \n",
      "7011465 2020-02-19   ZUMZ  32.490002 -0.015082  0.009063 -0.170937 -0.534687   \n",
      "7011466 2020-02-19   ZYXI  10.210000  0.028404  0.045714  0.240000  0.040000   \n",
      "\n",
      "           SPORTS   SCIENCE    COMEDY  ...  FIFTY     MEDIA  EDUCATION  \\\n",
      "0        0.090144  0.105193  0.090873  ...    0.0  0.000000        0.0   \n",
      "1        0.090144  0.105193  0.090873  ...    0.0  0.000000        0.0   \n",
      "2        0.090144  0.105193  0.090873  ...    0.0  0.000000        0.0   \n",
      "3        0.090144  0.105193  0.090873  ...    0.0  0.000000        0.0   \n",
      "4        0.090144  0.105193  0.090873  ...    0.0  0.000000        0.0   \n",
      "...           ...       ...       ...  ...    ...       ...        ...   \n",
      "7011462 -0.155556  0.000000  0.000000  ...    0.0  0.113636        0.0   \n",
      "7011463 -0.155556  0.000000  0.000000  ...    0.0  0.113636        0.0   \n",
      "7011464 -0.155556  0.000000  0.000000  ...    0.0  0.113636        0.0   \n",
      "7011465 -0.155556  0.000000  0.000000  ...    0.0  0.113636        0.0   \n",
      "7011466 -0.155556  0.000000  0.000000  ...    0.0  0.113636        0.0   \n",
      "\n",
      "         WEIRD NEWS  LATINO VOICES  GOOD NEWS  ARTS & CULTURE  THE WORLDPOST  \\\n",
      "0          0.000000            0.0        0.0             0.0            0.0   \n",
      "1          0.000000            0.0        0.0             0.0            0.0   \n",
      "2          0.000000            0.0        0.0             0.0            0.0   \n",
      "3          0.000000            0.0        0.0             0.0            0.0   \n",
      "4          0.000000            0.0        0.0             0.0            0.0   \n",
      "...             ...            ...        ...             ...            ...   \n",
      "7011462    0.233333            0.0        0.0             0.0            0.0   \n",
      "7011463    0.233333            0.0        0.0             0.0            0.0   \n",
      "7011464    0.233333            0.0        0.0             0.0            0.0   \n",
      "7011465    0.233333            0.0        0.0             0.0            0.0   \n",
      "7011466    0.233333            0.0        0.0             0.0            0.0   \n",
      "\n",
      "         WORLD NEWS  U.S. NEWS  \n",
      "0           0.00000   0.000000  \n",
      "1           0.00000   0.000000  \n",
      "2           0.00000   0.000000  \n",
      "3           0.00000   0.000000  \n",
      "4           0.00000   0.000000  \n",
      "...             ...        ...  \n",
      "7011462     0.00846   0.008407  \n",
      "7011463     0.00846   0.008407  \n",
      "7011464     0.00846   0.008407  \n",
      "7011465     0.00846   0.008407  \n",
      "7011466     0.00846   0.008407  \n",
      "\n",
      "[7011467 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "big_df = ml.dataframe_union(stock_dfs, daily_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df377f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:103.12270\n",
      "[50]\tvalidation_0-rmse:109.69303\n",
      "[100]\tvalidation_0-rmse:111.31208\n",
      "[150]\tvalidation_0-rmse:112.71639\n",
      "[200]\tvalidation_0-rmse:113.13400\n",
      "[250]\tvalidation_0-rmse:114.61607\n",
      "[300]\tvalidation_0-rmse:116.61246\n",
      "[350]\tvalidation_0-rmse:115.50596\n",
      "[400]\tvalidation_0-rmse:114.56095\n",
      "[450]\tvalidation_0-rmse:116.58673\n",
      "[500]\tvalidation_0-rmse:115.04970\n",
      "[550]\tvalidation_0-rmse:114.91033\n",
      "[600]\tvalidation_0-rmse:116.23943\n",
      "[650]\tvalidation_0-rmse:114.18118\n",
      "[700]\tvalidation_0-rmse:115.57354\n",
      "[750]\tvalidation_0-rmse:113.75887\n",
      "[800]\tvalidation_0-rmse:114.38235\n",
      "[850]\tvalidation_0-rmse:117.42115\n",
      "[900]\tvalidation_0-rmse:118.59006\n",
      "[950]\tvalidation_0-rmse:116.83502\n",
      "[999]\tvalidation_0-rmse:116.81810\n",
      "\n",
      "=== MODEL PERFORMANCE ===\n",
      "RMSE: 116.818106\n",
      "MAE:  1.135918\n",
      "R²:   -0.282495\n"
     ]
    }
   ],
   "source": [
    "# Experiment with 30 day return\n",
    "x_features = ['Open'] + list(news_df['category'].unique())\n",
    "\n",
    "X = big_df[x_features]\n",
    "y_30d = big_df['r_30d']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_30d, test_size=0.2, random_state=42)\n",
    "\n",
    "N_EST = 1000\n",
    "LAMBDA = 0.05\n",
    "MAX_DEPTH = 6\n",
    "SUB_SAMP = 0.8\n",
    "OBJECTIVE = \"reg:squarederror\"\n",
    "METHOD = \"hist\"\n",
    "\n",
    "model_30d = xgb.XGBRegressor(\n",
    "    n_estimators = N_EST,\n",
    "    learning_rate = LAMBDA,\n",
    "    max_depth = MAX_DEPTH,\n",
    "    subsample = SUB_SAMP,\n",
    "    objective = OBJECTIVE,\n",
    "    tree_method = METHOD\n",
    ")\n",
    "\n",
    "model_30d.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_test,y_test)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "predictions = model_30d.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"\\n=== MODEL PERFORMANCE ===\")\n",
    "print(f\"RMSE: {rmse:,.6f}\")\n",
    "print(f\"MAE:  {mae:,.6f}\")\n",
    "print(f\"R²:   {r2:,.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c9824",
   "metadata": {},
   "source": [
    "# XGBoost Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b88ba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stock_dfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m    At this point:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m        - stock_dfs: dictionary with ticker as key, DF as value\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m                - Target is the designated time horizon of that modelSo \u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m all_rows \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 16\u001b[0m all_dates \u001b[38;5;241m=\u001b[39m \u001b[43mstock_dfs\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_0d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_1d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_7d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_30d\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m cols\u001b[38;5;241m.\u001b[39mextend(all_cats)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stock_dfs' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    At this point:\n",
    "        - stock_dfs: dictionary with ticker as key, DF as value\n",
    "            - Gather list of tickers being used through stock_dfs.keys()\n",
    "            - stock_dfs[...]\n",
    "                - Date, Open, Close, Ticker, r_0d, r_1d, r_7d, r_30d\n",
    "        - daily_sentiment: DF holding sentiment scores\n",
    "            - date, category (42 total), avg_sentiment, article_count\n",
    "    \n",
    "    The plan:\n",
    "        - For each time horizon create an XGBoost Model\n",
    "            - Each model gets all 3511 stock openings and the scores of that day\n",
    "                - Target is the designated time horizon of that modelSo \n",
    "\"\"\"\n",
    "all_rows = []\n",
    "all_dates = stock_dfs['A']['Date']\n",
    "\n",
    "cols = ['Date', 'Ticker', 'Open', 'r_0d', 'r_1d', 'r_7d', 'r_30d']\n",
    "cols.extend(all_cats)\n",
    "\n",
    "for d in all_dates:\n",
    "    # Get dictionary of daily sentiments\n",
    "    sent_df = daily_sentiment[daily_sentiment['date'] == d]\n",
    "    daily_sent_scores = [sent_df[sent_df['category'] == cat]['avg_sentiment'].item() for cat in all_cats]\n",
    "    \n",
    "    # Iterate over tickers\n",
    "    for ticker, df in stock_dfs.items():\n",
    "        date, open, close, tick, r0, r1, r7, r30 = df[df['Date'] == d].values[0]\n",
    "        \n",
    "        row = [d, tick, open, r0, r1, r7, r30] # Get the date and stock ticker\n",
    "        row.extend(daily_sent_scores)\n",
    "        \n",
    "        all_rows.append(row)\n",
    "\n",
    "big_df = pd.DataFrame(data=all_rows, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afcda3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Open'] + all_cats\n",
    "X = big_df[feature_cols]\n",
    "\n",
    "y_0d = big_df['r_0d']\n",
    "y_1d = big_df['r_1d']\n",
    "y_7d = big_df['r_7d']\n",
    "y_30d = big_df['r_30d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dcf00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EST = 1000\n",
    "LAMBDA = 0.05\n",
    "MAX_DEPTH = 6\n",
    "EVAL_MET = \"mse\"\n",
    "\n",
    "model_0d = xgb.XGBRegressor(\n",
    "    n_estimators = N_EST,\n",
    "    learning_rate = LAMBDA,\n",
    "    max_depth= MAX_DEPTH,\n",
    "    eval_metric= EVAL_MET\n",
    ")\n",
    "\n",
    "model_1d = xgb.XGBRegressor(\n",
    "    n_estimators = N_EST,\n",
    "    learning_rate = LAMBDA,\n",
    "    max_depth= MAX_DEPTH,\n",
    "    eval_metric= EVAL_MET\n",
    ")\n",
    "\n",
    "model_7d = xgb.XGBRegressor(\n",
    "    n_estimators = N_EST,\n",
    "    learning_rate = LAMBDA,\n",
    "    max_depth= MAX_DEPTH,\n",
    "    eval_metric= EVAL_MET\n",
    ")\n",
    "\n",
    "model_30d = xgb.XGBRegressor(\n",
    "    n_estimators = N_EST,\n",
    "    learning_rate = LAMBDA,\n",
    "    max_depth= MAX_DEPTH,\n",
    "    eval_metric= EVAL_MET\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
